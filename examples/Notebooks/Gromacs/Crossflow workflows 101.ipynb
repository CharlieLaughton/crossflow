{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An introduction to Crossflow workflows\n",
    "\n",
    "In this notebook you will see how a simple MD simulation job can be converted from its normal command-line form into a Python function using tools in *Crossflow*.\n",
    "\n",
    "Then you will see how it's easy to chain jobs together to create a workflow.\n",
    "\n",
    "The notebook assumes you have a basic knowledge of *Gromacs*, and the Python package *MDTraj*, and that both of these are installed on the computer you are running this notebook on.\n",
    "\n",
    "----\n",
    "\n",
    "### Part 1: running jobs the conventional way\n",
    "Have a look at the contents of this directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see:\n",
    "\n",
    "    Crossflow workflows 101.ipynb : This notebook\n",
    "    bpti.gro                      : Coordinates for BPTI in Gromacs .gro format\n",
    "    bpti.top                      : Gromacs topology file for BPTI\n",
    "    em.mdp                        : A Gromacs .mdp file defining an energy minimisation job\n",
    "    nvt.mdp                       : a Gromacs .mdp file defining a short NVT MD simulation\n",
    "    \n",
    "Let's begin by running the energy minimisation job interactively in the conventional way. \n",
    "\n",
    "First we run grompp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gmx grompp -f em.mdp -c bpti.gro -p bpti.top -o bpti-em.tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming everything there went as expected, now we can run the energy minimisation itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gmx mdrun -s bpti-em.tpr -c bpti-em.gro -g bpti-em.log -o bpti-em.trr -e bpti-em.edr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the job completed without errors, you should see the output files in the current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the log file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat bpti-em.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Turning this into Python\n",
    "\n",
    "OK. Now you will see how you can turn the energy minimisation job from something you run on the command line (in this situation, within a Jupyter notebook, by using the \"!\" special command) into a pure Python function.\n",
    "\n",
    "The function will take a .tpr file as the input, and return the .gro and .log files when the job completes. For now, you can assume you are not that bothered about what's in the .edr and .trr files.\n",
    "\n",
    "So your aim is something like this:\n",
    "\n",
    "    grofile, logfile = mdrun(tprfile)\n",
    "    \n",
    "---\n",
    "\n",
    "Begin by importing the required submodules from crossflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crossflow import filehandling, kernels, clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you create the function, which in xflowlib is called a **Kernel**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = kernels.SubprocessKernel('gmx mdrun -s x.tpr -c x.gro -g x.log -e x.edr -o x.trr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that creating the kernel involves providing a template for the command you want to run. The names of the files in the template are completely up to you (e.g. you could use \"system.tpr\", etc. instead of \"x.tpr\") - but in general make sure the filenames have the appropriate extensions.\n",
    "\n",
    "---\n",
    "\n",
    "Now you have to tell the kernel what files are inputs, and what are outputs. To do this you pass *lists* of strings that correspond to the filenames in the template above. \n",
    "\n",
    "**NB:** the order of the strings in the inputs list defines the order that input variables will be passed to the kernel, and the order of the strings in the output list defines the order that the outputs from the function will appear in.\n",
    "\n",
    "**NB2:** You only get the outputs you ask for. So although the job is going to produce trajectory (x.trr) and energy(x.edr) files, you are not going to see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the kernel the signature: grofile, logfile = mdrun.run(tprfile)\n",
    "md.set_inputs(['x.tpr'])\n",
    "md.set_outputs(['x.gro', 'x.log'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's about it - your new function is ready for use.\n",
    "\n",
    "However, your data is not quite ready. Xbowflow is designed to work with distributed computing facilities that may not share a common file system. So before you can use the function, you need to get the input .tpr file into a suitable globally-accessible variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = filehandling.FileHandler()\n",
    "tprfile = fh.load('bpti-em.tpr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a crossflow client to serve your local compute system, and then submit the job (the function and its arguments) to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = clients.Client()\n",
    "grofile, logfile = client.submit(md, tprfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job is now submitted for computation, which takes place in the background. The output variables `grofile` and `logfile` are `Futures`, whose final values are obtained by calling their `result()` methods. Use this to save the outputs to local files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile.result().save('test.log')\n",
    "grofile.result().save('test.gro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat test.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat test.gro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: A workflow\n",
    "\n",
    "Let's make a workflow that runs a grompp job, then immediately the md (or energy minimisation) job.\n",
    "\n",
    "You already have a kernel that can run *mdrun*, but you need to build one to run *grompp*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a kernel with the signature: tprfile = grompp.run(mdpfile, grofile, topfile):\n",
    "grompp = kernels.SubprocessKernel('gmx grompp -f x.mdp -c x.gro -p x.top -o x.tpr -maxwarn 1')\n",
    "grompp.set_inputs(['x.mdp', 'x.gro', 'x.top'])\n",
    "grompp.set_outputs(['x.tpr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables from the required input files:\n",
    "emfile = fh.load('em.mdp')\n",
    "start_crds = fh.load('bpti.gro')\n",
    "topfile = fh.load('bpti.top')\n",
    "# Run the job:\n",
    "em_tprfile_future = client.submit(grompp, emfile, start_crds, topfile)\n",
    "em_tprfile = em_tprfile_future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from this kernel should be ready for use in the mdrun kernel - let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the energy minimisation:\n",
    "em_crds, em_logfile = client.submit(md, em_tprfile_future)\n",
    "em_logfile.result().save('em.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat em.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Exercise - a bigger workflow\n",
    "\n",
    "Now we add the second simulation stage - the NVT MD - into your workflow.\n",
    "\n",
    "Notice:\n",
    "1. You don't need to make any new kernels - you can re-use the ones you have.\n",
    "2. Don't forget that you need to create a FileHandle for the file nvt.mdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A workflow that runs an energy minimisation and then an NVT MD simulation\n",
    "em_tprfile = client.submit(grompp, emfile, start_crds, topfile)\n",
    "em_crds, em_logfile = client.submit(md, em_tprfile)\n",
    "nvtfile = fh.load('nvt.mdp')\n",
    "nvt_tprfile = client.submit(grompp, nvtfile, em_crds, topfile)\n",
    "nvt_crds, nvt_logfile = client.submit(md, nvt_tprfile)\n",
    "nvt_logfile.result().save('nvt.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: A better workflow\n",
    "\n",
    "Let's improve the workflow. Firstly, it would be nice if the NVT simulation job also returned the trajectory file. You don't want this for the EM job, so what that means is that you need to make a second mdrun-type kernel. Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_with_traj = md.copy()\n",
    "md_with_traj.set_outputs(['x.gro', 'x.log', 'x.trr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The copy() convenience method saves you having to rewrite the kernel from scratch, if  it's just a tweak on an existing one. But it is also neccessary if you want to tweak a kernel that has already been used in a client.submit() call (if you want to understand why, see the dask.distributed documentation about 'pure' vs. 'impure' functions).\n",
    "\n",
    "Next, notice that both grompp jobs in the workflow above take the same topology file as an argument - in effect, it's a constant. In such cases, you can define it as such at the time you create the kernel, and then you don't have to include it in the list of arguments when you call it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grompp2 = grompp.copy()\n",
    "grompp2.set_constant('x.top', topfile)\n",
    "# Now the new improved workflow:\n",
    "em_tprfile = client.submit(grompp2, emfile, start_crds)\n",
    "em_crds, em_logfile = client.submit(md, em_tprfile)\n",
    "nvt_tprfile = client.submit(grompp2, nvtfile, em_crds)\n",
    "nvt_crds, nvt_logfile, nvt_traj = client.submit(md_with_traj, nvt_tprfile)\n",
    "nvt_logfile.result().save('nvt.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: interfacing with more Python\n",
    "\n",
    "At this stage you may be thinking \"OK - but nothing here I couldn't do with a bash script\". The power of the workflow comes when you interface your new pythonized-MD functions with other Python tools.\n",
    "\n",
    "Let's make use of the *MDTraj* package for analysis of MD trajectory data. You will use it to calculate the RMSD of the trajectory frames from the starting structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as mdt\n",
    "traj = mdt.load(nvt_traj.result(), top=start_crds)\n",
    "print(traj)\n",
    "# Calculate the rmsd of each frame from the first:\n",
    "print(mdt.rmsd(traj, traj[0], atom_indices=traj.topology.select('protein')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make your workflow identify which snapshot from your trajectory has the highest RMSD from the starting structure, and then energy minimise that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rmsdlist = mdt.rmsd(traj, traj[0], atom_indices=traj.topology.select('protein'))\n",
    "i = np.argmax(rmsdlist)\n",
    "print('Energy minimising snapshot {}'.format(i))\n",
    "selected_snapshot = traj[i]\n",
    "em2_tprfile = client.submit(grompp2, emfile, selected_snapshot)\n",
    "em2_crds, em2_logfile = client.submit(md, em2_tprfile)\n",
    "em2_crds.result().save('max_rmsd.gro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7: Putting it all together\n",
    "\n",
    "Here is a Python function that in effect does all the above: takes a set of starting coordinates, a topology file, and two .mdp files (one for an energy minimisation, one for an MD run), runs the workflow and then returns the energy-minimised structure of the snapshot with the highest RMSD from the starting structure. The function does everything, including creating the required kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_workflow(crd_filename, top_filename, em_mdp_filename, md_mdp_filename):\n",
    "    # Over to you!\n",
    "    # Load data:\n",
    "    start_crds = fh.load(crd_filename)\n",
    "    topfile = fh.load(top_filename)\n",
    "    emfile = fh.load(em_mdp_filename)\n",
    "    mdfile = fh.load(md_mdp_filename)\n",
    "    \n",
    "    # Create kernels:\n",
    "    grompp = kernels.SubprocessKernel('gmx grompp -f x.mdp -c x.gro -p x.top -o x.tpr -maxwarn 1')\n",
    "    grompp.set_inputs(['x.mdp', 'x.gro'])\n",
    "    grompp.set_constant('x.top', topfile)\n",
    "    grompp.set_outputs(['x.tpr'])\n",
    "    \n",
    "    md = kernels.SubprocessKernel('gmx mdrun -s x.tpr -c x.gro -g x.log -e x.edr -o x.trr')\n",
    "    md.set_inputs(['x.tpr'])\n",
    "    md.set_outputs(['x.gro', 'x.log'])\n",
    "    \n",
    "    md_with_traj = md.copy()\n",
    "    md_with_traj.set_outputs(['x.gro', 'x.log', 'x.trr'])\n",
    "    \n",
    "    # Run workflow (note nested client.submits() - compact but not neccessary!):\n",
    "    em_crds, em_logfile = client.submit(md, client.submit(grompp, emfile, start_crds))\n",
    "    md_crds, md_logfile, md_traj = client.submit(md_with_traj, client.submit(grompp, mdfile, em_crds))\n",
    "    traj = mdt.load(md_traj.result(), top=start_crds)\n",
    "    rmsdlist = mdt.rmsd(traj, traj[0], atom_indices=traj.topology.select('protein'))\n",
    "    i = np.argmax(rmsdlist)\n",
    "    print('Energy minimising snapshot {}'.format(i))\n",
    "    em2_crds, em2_logfile = client.submit(md, client.submit(grompp, emfile, traj[i]))\n",
    "    \n",
    "    # Return final structure:\n",
    "    return em2_crds.result()\n",
    "\n",
    "# Test the workflow:\n",
    "final_crds = my_workflow('bpti.gro', 'bpti.top', 'em.mdp', 'nvt.mdp')\n",
    "final_crds.save('final_coordinates.gro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
